{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "#read file\n",
    "df = pd.read_csv('/datasets/users_behavior.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>58.0</td>\n",
       "      <td>344.56</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15823.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>57.0</td>\n",
       "      <td>431.64</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3738.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>132.40</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21911.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2538.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>90.0</td>\n",
       "      <td>665.41</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17358.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0\n",
       "5   58.0   344.56      21.0  15823.37         0\n",
       "6   57.0   431.64      20.0   3738.90         1\n",
       "7   15.0   132.40       6.0  21911.60         0\n",
       "8    7.0    43.39       3.0   2538.67         1\n",
       "9   90.0   665.41      38.0  17358.61         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smart: 0.69 \n",
      "ultra: 0.31 \n",
      "\n",
      "smart statistics\n",
      "            median     mean     std  min      max\n",
      "calls        60.0     58.5    25.9  0.0    198.0\n",
      "minutes     410.6    405.9   184.5  0.0   1390.2\n",
      "messages     28.0     33.4    28.2  0.0    143.0\n",
      "mb_used   16506.9  16208.5  5870.5  0.0  38552.6\n",
      "is_ultra      0.0      0.0     0.0  0.0      0.0 \n",
      "\n",
      "\n",
      "ultra statistics\n",
      "            median     mean      std  min      max\n",
      "calls        74.0     73.4     43.9  0.0    244.0\n",
      "minutes     502.6    511.2    308.0  0.0   1632.1\n",
      "messages     38.0     49.4     47.8  0.0    224.0\n",
      "mb_used   19308.0  19468.8  10087.2  0.0  49745.7\n",
      "is_ultra      1.0      1.0      0.0  1.0      1.0 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#viewing some statistics\n",
    "print('smart:',round(df[df['is_ultra']==0].shape[0]/df.shape[0],2), \\\n",
    "      '\\nultra:', round(df[df['is_ultra']==1].shape[0]/df.shape[0],2),'\\n')\n",
    "stat={}\n",
    "for plan,mask in zip(['smart','ultra'],[df.eval('is_ultra == 0'),df.eval('is_ultra == 1')]):\n",
    "    stat[plan]=pd.concat([df.loc[mask,:].median(), \\\n",
    "                        df.loc[mask,:].mean(), \\\n",
    "                        df.loc[mask,:].std(), \\\n",
    "                        df.loc[mask,:].min(), \\\n",
    "                        df.loc[mask,:].max()], axis=1)\n",
    "    stat[plan].columns=['median','mean','std','min','max']\n",
    "    stat[plan]=stat[plan].round(1)\n",
    "    print(plan , 'statistics\\n',stat[plan],'\\n\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data to train set (60%), validation (20%) and test (20%) sets \n",
    "sets = {}\n",
    "sets['train'], df_val_test = train_test_split(df, test_size=0.4, random_state=12345)\n",
    "sets['valid'], sets['test'] = train_test_split(df_val_test, test_size=0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining features and tagets\n",
    "\n",
    "sets_parts = {}\n",
    "for set_name in sets.keys():\n",
    "    sets_parts[set_name + '_' + 'features'] = sets[set_name].drop(['is_ultra'], axis=1)\n",
    "    sets_parts[set_name + '_' + 'target'] = sets[set_name]['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree trainings\n",
    "\n",
    "acc_DT = {}\n",
    "mean_DT = {}\n",
    "for max_depth in range(1,6):\n",
    "    model = DecisionTreeClassifier(random_state=12340+max_depth, max_depth=max_depth)\n",
    "    model.fit(sets_parts['train_features'], sets_parts['train_target'])\n",
    "    #predict on validation set\n",
    "    predictions = model.predict(sets_parts['valid_features'])\n",
    "    acc_DT[max_depth]=(accuracy_score(sets_parts['valid_target'], predictions))\n",
    "    mean_DT[max_depth]=predictions.mean()\n",
    "#    acc_DT[max_depth]=model.score(sets_parts['valid_features'],sets_parts['valid_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max accuracy:  0.7853810264385692  max_depth:  3  mean predictions:  0.17884914463452567\n"
     ]
    }
   ],
   "source": [
    "max_depth = max(acc_DT, key=acc_DT.get)\n",
    "print('max accuracy: ', acc_DT[max_depth],' max_depth: ', max_depth, ' mean predictions: ', mean_DT[max_depth])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest trainings\n",
    "\n",
    "acc_RF = {}\n",
    "mean_RF = {}\n",
    "for n_estimators in range(4,16):\n",
    "    model = RandomForestClassifier(random_state=12340+n_estimators, n_estimators=n_estimators)\n",
    "    model.fit(sets_parts['train_features'], sets_parts['train_target'])\n",
    "    #predict on validation set\n",
    "    predictions = model.predict(sets_parts['valid_features'])\n",
    "    acc_RF[n_estimators]=(accuracy_score(sets_parts['valid_target'], predictions))\n",
    "    mean_RF[n_estimators]=predictions.mean()\n",
    "#    acc_RF[n_estimators]=model.score(sets_parts['valid_features'],sets_parts['valid_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max accuracy:  0.7900466562986003 n_estimators:  10  mean predictions:  0.19906687402799378\n"
     ]
    }
   ],
   "source": [
    "n_estimators = max(acc_RF, key=acc_RF.get)\n",
    "print('max accuracy: ', acc_RF[n_estimators],'n_estimators: ', n_estimators, ' mean predictions: ', mean_RF[n_estimators])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.7589424572317263  mean predictions:  0.08087091757387248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression training\n",
    "\n",
    "model = LogisticRegression(random_state=12345)\n",
    "model.fit(sets_parts['train_features'], sets_parts['train_target'])\n",
    "predictions = model.predict(sets_parts['valid_features'])\n",
    "acc_LR = (accuracy_score(sets_parts['valid_target'], predictions))\n",
    "mean_LR = predictions.mean()\n",
    "#model.score(sets_parts['valid_features'],sets_parts['valid_target'])\n",
    "print('accuracy: ', acc_LR, ' mean predictions: ', mean_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best trained model is Random Forest with  n_estimators = 10, accuracy = 0.79 and predictions mean = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30075364764492174"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([sets['train']['is_ultra'].mean(), sets['valid']['is_ultra'].mean()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30% of the set is classified as '1'. A constant prediction of zeros would result in an accuracy score of 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7060653188180405"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking accuracy score for a prediction of 0's\n",
    "random_pred = pd.Series(0,sets_parts['valid_target'].index)\n",
    "accuracy_score(sets_parts['valid_target'], random_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean predictions:  0.21162827617419722 Mean score:  0.7809241263633655 random seed:  12374\n"
     ]
    }
   ],
   "source": [
    "#training random forest with n=10 multiple times to check avarage score and best random seed\n",
    "mean_score = 0.79\n",
    "max_score = 0.79\n",
    "i_max_score = 10\n",
    "for i in range(0,50):\n",
    "    model = RandomForestClassifier(random_state=12340+i, n_estimators=10)\n",
    "    model.fit(sets_parts['train_features'], sets_parts['train_target'])\n",
    "    predictions = model.predict(sets_parts['valid_features'])\n",
    "    mean_predictions = np.mean([mean_predictions, predictions.mean()])\n",
    "    score = accuracy_score(sets_parts['valid_target'], predictions)\n",
    "    mean_score = np.mean([mean_score, score])\n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        i_max_score = i\n",
    "print('Mean predictions: ',mean_predictions, 'Mean score: ', mean_score, 'random seed: ',12340+i_max_score )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training final model and testing on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=12374,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final model\n",
    "final_model = RandomForestClassifier(random_state=12340+i_max_score, n_estimators=10)\n",
    "features = pd.concat([sets_parts['train_features'], sets_parts['valid_features']], ignore_index=True)\n",
    "target = pd.concat([sets_parts['train_target'], sets_parts['valid_target']], ignore_index=True)\n",
    "final_model.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean predictions:  0.23483670295489892 Score:  0.7947122861586314\n"
     ]
    }
   ],
   "source": [
    "#Testing the model on test set\n",
    "predictions = final_model.predict(sets_parts['test_features'])\n",
    "print('Mean predictions: ',predictions.mean(), 'Score: ', accuracy_score(sets_parts['test_target'], predictions) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "- Best model is Random Forest with n = 10 \n",
    "- Achieved a score of 0.794, compared with a dummy score of 0.7\n",
    "- Achieved predictions ratio of 0.234, compared with 0.3 true ratio in training set "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
